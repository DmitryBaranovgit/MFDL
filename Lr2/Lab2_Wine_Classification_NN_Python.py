# -*- coding: utf-8 -*-
"""Баранов Д.А. ИВТ 2.1. Laboratory_work_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1h1oGqY0wBUFI01WpDIbihCaUWzf10XAR

Баранов Д.А. ИВТ 2.1
Лабораторная работа №2

# Задание

Используя модуль **datasets** библиотеки **sklearn**, загрузите базу вин (`.load_wine()`).

Используя шаблон ноутбука, выполните загрузку, подготовку и предобработку данных. Обязательное условие: разделение данных на три выборки осуществляется по шаблону (изменять параметры подготовки данных запрещается)!

Проведите серию экспериментов и добейтесь максимальной точности классификации на тестовой выборке выше 94%.

---

С помощью метода `.summary()` зафиксируйте количество параметров созданной вами нейронной сети.

#Шаблон ноутбука
"""

# Commented out IPython magic to ensure Python compatibility.
# Последовательная модель НС
from tensorflow.keras.models import Sequential

# Основные слои
from tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization

# Утилиты для to_categorical()
from tensorflow.keras import utils

# Алгоритмы оптимизации для обучения модели
from tensorflow.keras.optimizers import Adam

# EarlyStopping
from tensorflow.keras.callbacks import EarlyStopping

# Библиотека для работы с массивами
import numpy as np

# Отрисовка графиков
import matplotlib.pyplot as plt

# Разделение данных на выборки
from sklearn.model_selection import train_test_split

# Для загрузки датасета
from sklearn.datasets import load_wine

# Отрисовка изображений в ноутбуке, а не в консоли или файле
# %matplotlib inline

"""##Описание базы

1. Датасет состоит из набора данных о винах и их классах.
2. Данные по одному вину хранятся в numpy-массиве `x_data`: (`13` параметров).
3. В датасете `3` класса вин: `y_data`.
4. Количество примеров: `178`.
"""

x_data = load_wine()['data']              # Загрузка набора данных о винах
y_data = load_wine()['target']            # Загрузка классов вин

print('Размерность x_data -', x_data.shape)
print('Размерность y_data -', y_data.shape)
print()

# Вывод примера данных
print('Данные по первому вину:',x_data[0])
print('Класс вина:',y_data[0])

"""##Подготовка данных"""

# Перевод в one hot encoding
y_data = utils.to_categorical(y_data, 3)

# Разбиение наборов на общую и тестовую выборки
x_all, x_test, y_all, y_test = train_test_split(x_data,
                                                y_data,
                                                test_size=0.1,
                                                shuffle=True,
                                                random_state = 6)

# Разбиение общей выборки на обучающую и проверочную
x_train, x_val, y_train, y_val = train_test_split(x_all,
                                                  y_all,
                                                  test_size=0.1,
                                                  shuffle=True,
                                                  random_state = 6)

print(x_train.shape)
print(y_train.shape)
print()
print(x_val.shape)
print(y_val.shape)

# ваше решение

# Исправление формы данных
# y_train = np.squeeze(y_train)
# y_val = np.squeeze(y_val)
# y_test = np.squeeze(y_test)

# Проверка форм
# print("Форма y_train:", y_train.shape)
# print("Форма y_val:", y_val.shape)
# print("Форма y_test:", y_test.shape)

# Построение модели
model = Sequential()
model.add(Dense(256, activation = 'relu', input_shape = (x_train.shape[1],)))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Dense(128, activation = 'relu'))
model.add(Dropout(0.4))
model.add(Dense(64, activation = 'relu'))
model.add(Dropout(0.3))
model.add(Dense(3, activation = 'softmax'))

# Сводка
model.summary()

# Компиляция
model.compile(optimizer = Adam(learning_rate = 0.0005),
              loss = 'categorical_crossentropy',
              metrics = ['accuracy'])

# Обучение с ранней остановкой
early_stop = EarlyStopping(
    monitor = 'val_accuracy',
    patience = 30,
    restore_best_weights = True
)

# Обучение модели
history = model.fit(x_train, y_train,
                    validation_data = (x_val, y_val),
                    epochs = 500,
                    batch_size = 16,
                    callbacks = [early_stop],
                    verbose = 1)

# Оценка на тестовой выборке
loss, accuracy = model.evaluate(x_test, y_test, verbose = 0)
print(f"\n Точность на тестовой выборке: {accuracy * 100:.2f}%")

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'], label = 'Train Accuracy')
plt.plot(history.history['val_accuracy'], label = 'Validation Accuracy')
plt.legend()
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Model Accuracy')
plt.grid(True)
plt.show()